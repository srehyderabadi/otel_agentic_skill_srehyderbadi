# CNCF Hyderabad â€” OTel Demo with Agent Skills

A full observability demo that showcases **OpenTelemetry auto-instrumentation** on a Python microservices app running in `k3d`, powered by **AI agent skills** for zero-friction operations.

---

## ğŸ“Š Presentation Decks

- [Blind to Boundless: Agentic OpenTelemetry](./presentation/Blind_to_Boundless-Agentic_OTel.pdf) â€” Main presentation cover
- [Agent Skills vs Direct Scripts](./presentation/directscripts_vs_agentskills.pdf) â€” Comparison guide

---

## ğŸ“‹ Prerequisites

Before running this demo, ensure the following tools and utilities are installed and available in your `PATH`.

### âœ… Run the Validation Script First

```bash
bash validate_setup.sh
```

This script checks every required tool, validates versions, and reports pass/fail for your environment. Run it before anything else.

---

### ğŸ”§ Required Tools & Minimum Versions

| Tool / Utility      | Purpose                                      | Install Reference                                                   | Min Version |
| ------------------- | -------------------------------------------- | ------------------------------------------------------------------- | ----------- |
| **Docker**          | Build & run container images                 | [docs.docker.com](https://docs.docker.com/get-docker/)              | 20.x        |
| **k3d**             | Lightweight Kubernetes cluster on Docker     | [k3d.io](https://k3d.io/stable/#installation)                       | 5.x         |
| **kubectl**         | Kubernetes CLI â€” apply manifests, debug pods | [kubernetes.io](https://kubernetes.io/docs/tasks/tools/)            | 1.24+       |
| **Helm**            | Install OTel Operator & cert-manager         | [helm.sh](https://helm.sh/docs/intro/install/)                      | 3.x         |
| **k6**              | Load testing / traffic generation            | [k6.io/docs](https://grafana.com/docs/k6/latest/set-up/install-k6/) | 0.45+       |
| **Python 3**        | App microservices runtime                    | [python.org](https://www.python.org/downloads/)                     | 3.10+       |
| **pip**             | Python package manager                       | Bundled with Python                                                 | â€”           |
| **curl**            | HTTP testing & health checks                 | Pre-installed on most systems                                       | â€”           |
| **jq** _(optional)_ | Pretty-print JSON in terminal                | [stedolan.github.io/jq](https://stedolan.github.io/jq/)             | 1.6+        |

### â˜ï¸ Platform Requirements

| Requirement           | Details                                                 |
| --------------------- | ------------------------------------------------------- |
| **OS**                | macOS or Linux (WSL2 on Windows with Docker Desktop)    |
| **RAM**               | â‰¥ 8 GB recommended (cluster + observability stack)      |
| **Disk**              | â‰¥ 5 GB free (for Docker images and k3d volumes)         |
| **Port 80 available** | k3d maps ingress to `localhost:80`                      |
| **Internet access**   | Helm chart pulls (cert-manager, OTel Operator) at setup |

---

## ğŸ—ï¸ Technology Stack

### Application Layer

| Component           | Technology       | Description                                            |
| ------------------- | ---------------- | ------------------------------------------------------ |
| **biryani-service** | Python + FastAPI | Serves biryani orders; upstream to order-service       |
| **chai-service**    | Python + FastAPI | Serves chai orders; upstream to order-service          |
| **order-service**   | Python + FastAPI | Orchestrates calls to biryani-service and chai-service |

### Kubernetes & Cluster

| Component              | Technology | Description                                                |
| ---------------------- | ---------- | ---------------------------------------------------------- |
| **Kubernetes cluster** | k3d + k3s  | Lightweight local cluster running inside Docker containers |
| **Ingress controller** | Traefik    | Bundled with k3s; routes all UI traffic via `localhost:80` |
| **Namespaces**         | Kubernetes | `apps`, `opentelemetry`, `observability`                   |

### OpenTelemetry

| Component                | Technology                      | Description                                                      |
| ------------------------ | ------------------------------- | ---------------------------------------------------------------- |
| **OTel Operator**        | cert-manager + OTel Operator    | Installed via Helm; manages auto-instrumentation injection       |
| **OTel Collector**       | OpenTelemetry Collector         | Receives OTLP traces & metrics; routes to configured backends    |
| **Instrumentation CR**   | `Instrumentation` (CRD)         | Defines SDK config, propagators, samplers, and exporter endpoint |
| **Auto-instrumentation** | `opentelemetry-distro` (Python) | Injected as init container; zero app code changes                |
| **OTLP Receiver**        | gRPC (4317) + HTTP (4318)       | Collector endpoints used by instrumented pods                    |

### Observability Backends

| Backend             | Role           | Profile   | UI Path                      |
| ------------------- | -------------- | --------- | ---------------------------- |
| **VictoriaMetrics** | Metrics store  | `initial` | Internal; queried by Grafana |
| **Jaeger**          | Trace store    | `initial` | `/jaeger`                    |
| **Prometheus**      | Metrics store  | `demo`    | Internal; queried by Grafana |
| **Tempo**           | Trace store    | `demo`    | Internal; queried by Grafana |
| **Loki**            | Log aggregator | `demo`    | Internal; queried by Grafana |
| **Grafana**         | Unified UI     | Both      | `/grafana`                   |

### Load Testing

| Component           | Technology | Description                                        |
| ------------------- | ---------- | -------------------------------------------------- |
| **Load generator**  | k6         | JavaScript-based scripts for healthy + error loads |
| **healthy_load.js** | k6 script  | 200 req/min hitting biryani + chai endpoints       |
| **error_load.js**   | k6 script  | 150 req/min mixing valid + invalid endpoints       |

### AI Agent Layer

| Component             | Description                                                                         |
| --------------------- | ----------------------------------------------------------------------------------- |
| **Agent Skills**      | Reusable skill definitions in `.agents/skills/` with shell scripts                  |
| **Workflows**         | Slash-command driven operations in `.agents/workflows/`                             |
| **Antigravity Agent** | Google DeepMind AI assistant that executes skills via plain English                 |
| **Copilot Prompts**   | VS Code Copilot Chat prompt files in `.github/prompts/` â€” same ops, different agent |

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ apps/                               # Python microservices source code
â”‚   â”œâ”€â”€ biryani_service/                # FastAPI biryani service
â”‚   â”œâ”€â”€ chai_service/                   # FastAPI chai service
â”‚   â””â”€â”€ order_service/                  # FastAPI order orchestrator
â”œâ”€â”€ k8s/
â”‚   â””â”€â”€ apps_manifests.yaml             # Kubernetes deployment + service manifests for apps
â”œâ”€â”€ observability/                      # Observability stack manifests
â”‚   â”œâ”€â”€ setup-cluster.sh               # Create k3d cluster with ingress port mapping
â”‚   â”œâ”€â”€ namespaces.yaml                # Kubernetes namespaces (apps, opentelemetry, observability)
â”‚   â”œâ”€â”€ otel-collector.yaml            # OTel Collector (both initial and demo ConfigMaps)
â”‚   â”œâ”€â”€ victoriametrics.yaml           # VictoriaMetrics deployment & service
â”‚   â”œâ”€â”€ jaeger.yaml                    # Jaeger all-in-one deployment & service
â”‚   â”œâ”€â”€ prometheus.yaml               # Prometheus deployment & service
â”‚   â”œâ”€â”€ tempo.yaml                    # Tempo deployment & service
â”‚   â”œâ”€â”€ loki.yaml                     # Loki deployment & service
â”‚   â”œâ”€â”€ grafana.yaml                  # Grafana with pre-configured datasources
â”‚   â”œâ”€â”€ ingress.yaml                  # Traefik ingress rules for all UIs
â”‚   â””â”€â”€ README.md                     # Phase 1 & 2 observability setup guide
â”œâ”€â”€ otel-instrumentation/              # OTel Operator model explainer & Instrumentation CR
â”‚   â””â”€â”€ README.md                     # Operator model demo guide
â”œâ”€â”€ k6_scripts/                        # k6 load-test scripts
â”‚   â”œâ”€â”€ healthy_load.js               # Healthy traffic (200 req/min)
â”‚   â””â”€â”€ error_load.js                 # Mixed error traffic (150 req/min)
â”œâ”€â”€ .agents/                           # AI agent skills and workflows (Antigravity)
â”‚   â”œâ”€â”€ skills/
â”‚   â”‚   â”œâ”€â”€ apply-otel-instrumentation/  # Install OTel Operator + inject instrumentation
â”‚   â”‚   â”œâ”€â”€ remove-otel-instrumentation/ # Strip instrumentation annotations + delete CR
â”‚   â”‚   â”œâ”€â”€ switch-otel-config/          # Switch OTel Collector profile (initial â†” demo)
â”‚   â”‚   â””â”€â”€ cluster-health-check/        # Full cluster health + OTel backend report
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ apply-otel-instrumentation.md
â”‚       â”œâ”€â”€ remove-otel-instrumentation.md
â”‚       â”œâ”€â”€ switch-otel-config.md
â”‚       â””â”€â”€ cluster-health-check.md
â”œâ”€â”€ .github/                           # VS Code Copilot Chat integration
â”‚   â”œâ”€â”€ copilot-instructions.md        # Always-on workspace context for Copilot
â”‚   â”œâ”€â”€ skills/                        # ğŸ¤– VS Code Copilot Agent Skills (plain-English auto-select)
â”‚   â”‚   â”œâ”€â”€ apply-otel-instrumentation/SKILL.md
â”‚   â”‚   â”œâ”€â”€ remove-otel-instrumentation/SKILL.md
â”‚   â”‚   â”œâ”€â”€ switch-otel-config/SKILL.md
â”‚   â”‚   â””â”€â”€ cluster-health-check/SKILL.md
â”‚   â””â”€â”€ prompts/                       # Alternative: manual prompt attach with #
â”‚       â”œâ”€â”€ apply-otel-instrumentation.prompt.md
â”‚       â”œâ”€â”€ remove-otel-instrumentation.prompt.md
â”‚       â”œâ”€â”€ switch-otel-config.prompt.md
â”‚       â””â”€â”€ cluster-health-check.prompt.md
â”œâ”€â”€ presentation/                      # Presentation decks
â”‚   â”œâ”€â”€ Blind_to_Boundless-Agentic_OTel.pdf
â”‚   â””â”€â”€ directscripts_vs_agentskills.pdf
â”œâ”€â”€ build_docker.sh                    # Build Docker images & import into k3d
â”œâ”€â”€ run_k6.sh                          # Interactive load test runner
â”œâ”€â”€ validate_setup.sh                  # âœ… Environment prerequisite validation script
â”œâ”€â”€ requirements.txt                   # Python dependencies for local dev
â””â”€â”€ SAMPLE_QUERIES.md                  # Sample validation queries for backends
```

---

## ğŸš€ Quick Start

### Step 1 â€” Validate Your Environment

```bash
bash validate_setup.sh
```

All checks must pass before proceeding.

### Step 2 â€” Create the Cluster

```bash
cd observability && ./setup-cluster.sh
```

This creates a k3d cluster named `cncf-hyd` with ingress on port 80.

### Step 3 â€” Deploy Observability Stack

```bash
cd observability
kubectl apply -f namespaces.yaml

# â”€â”€ Phase 1 backends (initial profile: VictoriaMetrics + Jaeger) â”€â”€
kubectl apply -f victoriametrics.yaml
kubectl apply -f jaeger.yaml

# â”€â”€ Phase 2 backends (demo profile: Prometheus + Tempo + Loki) â”€â”€â”€â”€
kubectl apply -f prometheus.yaml
kubectl apply -f tempo.yaml
kubectl apply -f loki.yaml

# â”€â”€ Shared: OTel Collector, Grafana, Ingress â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
kubectl apply -f otel-collector.yaml
kubectl apply -f grafana.yaml
kubectl apply -f ingress.yaml
```

> All backends are deployed upfront so both `initial` and `demo` OTel profiles work instantly when you switch â€” no extra `kubectl apply` needed later.

### Step 4 â€” Build & Deploy App Services

Build Docker images and import them into the k3d cluster:

```bash
./build_docker.sh
```

Deploy to Kubernetes:

```bash
kubectl apply -f k8s/apps_manifests.yaml
```

### Step 5 â€” Verify Deployment

```bash
# Check running pods
kubectl get pods -n apps

# Check services
kubectl get svc -n apps

# Check ingress
kubectl get ingress -n apps
```

---

## ğŸ¤– Agent Skills & Workflows

This project supports **two AI agents** â€” pick whichever you use:

### Antigravity (Google DeepMind)

Use plain-English prompts or slash commands in Antigravity chat:

| Slash Command                  | What It Does                                                  |
| ------------------------------ | ------------------------------------------------------------- |
| `/apply-otel-instrumentation`  | Install OTel Operator + inject auto-instrumentation into pods |
| `/remove-otel-instrumentation` | Strip instrumentation annotations + delete Instrumentation CR |
| `/switch-otel-config`          | Switch OTel Collector between `initial` and `demo` profiles   |
| `/cluster-health-check`        | Full cluster health report + active OTel backend status       |

Skills are defined in `.agents/skills/` and workflows in `.agents/workflows/`.

---

### VS Code Copilot Chat (GitHub Copilot)

> **Requires**: VS Code 1.99+ with GitHub Copilot extension enabled.

Four prompt files are available in `.github/prompts/`. Use them in Copilot Chat:

#### ğŸ¤– Agent Skills â€” Plain English (Recommended)

Four **Agent Skills** are defined in `.github/skills/`. Copilot reads each skill's `name` and `description` to automatically pick the right skill from your plain-English request â€” no slash commands needed.

**Just ask in plain English in Copilot Chat (Agent mode):**

| What you say (example)                             | Skill that gets selected      |
| -------------------------------------------------- | ----------------------------- |
| "apply otel instrumentation to my apps"            | `apply-otel-instrumentation`  |
| "remove otel from the cluster"                     | `remove-otel-instrumentation` |
| "check cluster health / how many services running" | `cluster-health-check`        |
| "switch to demo otel config"                       | `switch-otel-config`          |

Copilot matches your intent to the right `SKILL.md`, understands the steps, and executes them in the terminal â€” same experience as Antigravity.

#### ğŸ“ Prompt Files â€” Manual Attach (Alternative)

If you prefer explicit control, four prompt files are in `.github/prompts/`:

1. Open Copilot Chat â†’ click **ğŸ“** â†’ **Prompt...** â†’ select a file, or type `#` followed by the prompt filename.

> `.github/copilot-instructions.md` is loaded **automatically** by Copilot as workspace context â€” no action needed.

---

## ğŸ”­ OTel Backend Profiles

| Profile     | Traces | Metrics         | Logs | Activate via               |
| ----------- | ------ | --------------- | ---- | -------------------------- |
| **initial** | Jaeger | VictoriaMetrics | â€”    | Default after stack deploy |
| **demo**    | Tempo  | Prometheus      | Loki | `/switch-otel-config demo` |

> All Grafana datasources (VictoriaMetrics, Jaeger, Prometheus, Tempo, Loki) are **pre-configured** â€” no manual setup required.

---

## ğŸŒ Accessing UIs

| Service               | URL                         |
| --------------------- | --------------------------- |
| **Grafana**           | http://localhost:80/grafana |
| **Jaeger**            | http://localhost:80/jaeger  |
| **App (via ingress)** | http://localhost:80/order   |

---

## ğŸ¬ Demo Flow

1. **Baseline:** App running, observability stack up, no OTel instrumentation â†’ Jaeger shows no traces.
2. **Add OTel live:** Use `/apply-otel-instrumentation` â†’ Pods restart with injected Python SDK â†’ Jaeger shows full distributed traces.
3. **Generate load:** Run `./run_k6.sh` â†’ View live metrics in Grafana with Jaeger traces.
4. **Switch backends:** Use `/switch-otel-config demo` â†’ OTel Collector routes to Prometheus + Tempo + Loki.
5. **Load test again:** Run `./run_k6.sh` â†’ View end-to-end metrics in Prometheus/Grafana + Tempo traces + Loki logs.
6. **Clean up:** Use `/remove-otel-instrumentation` â†’ Pods restart clean, no traces emitted.

---

## ğŸ“ Notes

- The OTel Collector accepts OTLP on **gRPC port 4317** and **HTTP port 4318** inside the cluster.
- The OTel Operator requires **cert-manager** â€” the `apply-otel-instrumentation` skill installs it automatically.
- The `switch-otel-config` skill is idempotent â€” safe to run multiple times.
- k3d cluster name defaults to `cncf-hyd` (changeable in `observability/setup-cluster.sh`).
